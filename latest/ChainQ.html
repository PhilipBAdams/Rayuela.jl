<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Chain quantization (ChainQ) · Rayuela.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><h1>Rayuela.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">Home</a></li><li><span class="toctext">Library</span><ul><li><a class="toctext" href="PQ.html">Product quantization (PQ)</a></li><li><a class="toctext" href="OPQ.html">Optimized product quantization (OPQ)</a></li><li><a class="toctext" href="RVQ.html">Residual vector quantization (RVQ)</a></li><li><a class="toctext" href="ERVQ.html">Enhanced residual vector quantization (ERVQ)</a></li><li class="current"><a class="toctext" href="ChainQ.html">Chain quantization (ChainQ)</a><ul class="internal"><li><a class="toctext" href="#Reference-1">Reference</a></li></ul></li><li><a class="toctext" href="LSQ.html">Local search quantization (LSQ)</a></li></ul></li></ul></nav><article id="docs"><header><nav><ul><li>Library</li><li><a href="ChainQ.html">Chain quantization (ChainQ)</a></li></ul><a class="edit-page" href="https://github.com/una-dinosauria/Rayuela.jl/blob/master/docs/src/ChainQ.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Chain quantization (ChainQ)</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Chain-quantization-(ChainQ)-1" href="#Chain-quantization-(ChainQ)-1">Chain quantization (ChainQ)</a></h1><p>Chain quantization (ChainQ) is an non-orthogonal MCQ method.</p><p>ChainQ uses codebooks that only have a dependency with the previous and next codebook, therefore creating a chain. This allows the use of efficient polynomial (max-product) algorithms to find optimal encoding.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Rayuela.quantize_chainq" href="#Rayuela.quantize_chainq"><code>Rayuela.quantize_chainq</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">quantize_chainq(X, C, use_cuda=false, use_cpp=false) -&gt; B, ellapsed</code></pre><p>Given data and chain codebooks, find codes using the Viterbi algorithm chain quantizer.</p><p><strong>Arguments</strong></p><ul><li><code>X::Matrix{T}</code>: <code>d</code>-by-<code>n</code> data to quantize</li><li><code>C::Vector{Matrix{T}}</code>: <code>m</code>-long vector with <code>d</code>-by-<code>h</code> matrices. Each matrix is a pretrained codebook of size approximately <code>d</code>-by-<code>h</code>.</li><li><code>use_cuda::Bool</code>: whether to use a CUDA implementation</li><li><code>use_cpp::Bool</code>: whether to use a c++ implementation</li></ul><p>If both <code>use_cuda</code> and <code>use_cpp</code> are <code>true</code>, the CUDA implementation is used.</p><p><strong>Returns</strong></p><ul><li><code>B::Matrix{Int16}</code>: <code>m</code>-by-<code>n</code> matrix with the codes</li><li><code>ellapsed::Float64</code>: The time spent encoding</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/una-dinosauria/Rayuela.jl/blob/a3a1bed0e8b722ff0555d71230d3dadf7f9a01fb/src/ChainQ.jl#L291-L307">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Rayuela.train_chainq" href="#Rayuela.train_chainq"><code>Rayuela.train_chainq</code></a> — <span class="docstring-category">Function</span>.</div><div><div><pre><code class="language-none">train_chainq(X, m, h, R, B, C, niter, V=false) -&gt; C, B, R, error</code></pre><p>Train a chain quantizer. This method is typically initialized by <a href="OPQ.html#Optimized-product-quantization-(OPQ)-1">Optimized product quantization (OPQ)</a></p><p><strong>Arguments</strong></p><ul><li><code>X::Matrix{T}</code>: <code>d</code>-by-<code>n</code> data to quantize</li><li><code>m::Integer</code>: Number of codebooks</li><li><code>h::Integer</code>: Number of entries in each codebook (typically 256)</li><li><code>R::Matrix{T}</code>: <code>d</code>-by-<code>d</code> rotation matrix for initialization</li><li><code>B::Matrix{Int16}</code>: <code>m</code>-by-<code>n</code> matrix with pre-trained codes for initialization</li><li><code>C::Vector{Matrix{T}}</code>: <code>m</code>-long vector with <code>d</code>-by-<code>h</code> matrices. Each matrix is a pretrained codebook of size approximately <code>d</code>-by-<code>h</code>.</li><li><code>niter::Integer</code>: Number of iterations to use</li><li><code>V::Bool</code>: Whether to print progress</li></ul><p><strong>Returns</strong></p><ul><li><code>C::Vector{Matrix{T}}</code>: <code>m</code>-long vector with <code>d</code>-by-<code>h</code> matrix entries. Each matrix is a codebook of size approximately <code>d</code>-by-<code>h</code>.</li><li><code>B::Matrix{Int16}</code>: <code>m</code>-by-<code>n</code> matrix with the codes</li><li><code>R::Matrix{T}</code>: <code>d</code>-by-<code>d</code> optimized rotation matrix</li><li><code>error::T</code>: The quantization error after training</li></ul></div></div><a class="source-link" target="_blank" href="https://github.com/una-dinosauria/Rayuela.jl/blob/a3a1bed0e8b722ff0555d71230d3dadf7f9a01fb/src/ChainQ.jl#L354-L375">source</a></section><h2><a class="nav-anchor" id="Reference-1" href="#Reference-1">Reference</a></h2><p>Babenko, A., &amp; Lempitsky, V. (2015). Tree quantization for large-scale similarity search and classification. In <em>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em> (pp. 4240-4248). [<a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Babenko_Tree_Quantization_for_2015_CVPR_paper.pdf">PDF</a>]</p><footer><hr/><a class="previous" href="ERVQ.html"><span class="direction">Previous</span><span class="title">Enhanced residual vector quantization (ERVQ)</span></a><a class="next" href="LSQ.html"><span class="direction">Next</span><span class="title">Local search quantization (LSQ)</span></a></footer></article></body></html>
